{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "import csv\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import array\n",
    "import glob\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all training images, image names, and image labels from the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_train_img1 = 1700  #for labels 2,5,6\n",
    "num_train_img2 = 5000  #the rest except for 4\n",
    "num_train_img3 = 10000  #for label 4\n",
    "\n",
    "# create lists to store the image paths and image names\n",
    "artic_truck = []\n",
    "background = []\n",
    "bicycle = []\n",
    "bus = []\n",
    "car = []\n",
    "motorcycle = []\n",
    "nonM_vehicle = []\n",
    "pedes = []\n",
    "pickup_truck = []\n",
    "su_truck = []\n",
    "work_van = []\n",
    "\n",
    "\n",
    "artic_truck_name = []\n",
    "background_name = []\n",
    "bicycle_name = []\n",
    "bus_name = []\n",
    "car_name = []\n",
    "motorcycle_name = []\n",
    "nonM_vehicle_name = []\n",
    "pedes_name = []\n",
    "pickup_truck_name = []\n",
    "su_truck_name = []\n",
    "work_van_name = []\n",
    "\n",
    "# Each for loop extracts the image name (a number ID) and image path \n",
    "# for all training images in the corresponding category\n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/articulated_truck/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    artic_truck_name.append(found)\n",
    "    \n",
    "    path = './train/articulated_truck/%s' % name\n",
    "    artic_truck.append(path)\n",
    "\n",
    "    \n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/background/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    background_name.append(found)\n",
    "    \n",
    "    path = './train/background/%s' % name\n",
    "    background.append(path)\n",
    "\n",
    "\n",
    "for i in range(num_train_img1):\n",
    "    name = random.choice(os.listdir(\"./train/bicycle/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    bicycle_name.append(found)\n",
    "    \n",
    "    path = './train/bicycle/%s' % name\n",
    "    bicycle.append(path) \n",
    "    \n",
    "    \n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/bus/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    bus_name.append(found)\n",
    "    \n",
    "    path = './train/bus/%s' % name\n",
    "    bus.append(path)    \n",
    "    \n",
    "    \n",
    "for i in range(num_train_img3):\n",
    "    name = random.choice(os.listdir(\"./train/car/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    car_name.append(found)\n",
    "    \n",
    "    path = './train/car/%s' % name\n",
    "    car.append(path)    \n",
    "    \n",
    "for i in range(num_train_img1):\n",
    "    name = random.choice(os.listdir(\"./train/motorcycle/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    motorcycle_name.append(found)\n",
    "    \n",
    "    path = './train/motorcycle/%s' % name\n",
    "    motorcycle.append(path)\n",
    "\n",
    "for i in range(num_train_img1):\n",
    "    name = random.choice(os.listdir(\"./train/non-motorized_vehicle/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    nonM_vehicle_name.append(found)\n",
    "    \n",
    "    path = './train/non-motorized_vehicle/%s' % name\n",
    "    nonM_vehicle.append(path) \n",
    "    \n",
    "    \n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/pedestrian/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    pedes_name.append(found)\n",
    "    \n",
    "    path = './train/pedestrian/%s' % name\n",
    "    pedes.append(path)\n",
    "    \n",
    "\n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/pickup_truck/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    pickup_truck_name.append(found)\n",
    "    \n",
    "    path = './train/pickup_truck/%s' % name\n",
    "    pickup_truck.append(path)\n",
    "\n",
    "    \n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/single_unit_truck/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    su_truck_name.append(found)\n",
    "    \n",
    "    path = './train/single_unit_truck/%s' % name\n",
    "    su_truck.append(path) \n",
    "\n",
    "\n",
    "for i in range(num_train_img2):\n",
    "    name = random.choice(os.listdir(\"./train/work_van/\"))\n",
    "    m = re.search('0(.+?).jpg', name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "        found = int(float(found))\n",
    "    work_van_name.append(found)\n",
    "    \n",
    "    path = './train/work_van/%s' % name\n",
    "    work_van.append(path)\n",
    "    \n",
    "    \n",
    "# X = training_image \n",
    "# X = [artic_truck,background,bicycle,bus,car,motorcycle,nonM_vehicle,\n",
    "#      pedes,pickup_truck,su_truck,work_van]\n",
    "X = []\n",
    "X.append(artic_truck)\n",
    "X.append(background)\n",
    "X.append(bicycle)\n",
    "X.append(bus)\n",
    "X.append(car)\n",
    "X.append(motorcycle)\n",
    "X.append(nonM_vehicle)\n",
    "X.append(pedes)\n",
    "X.append(pickup_truck)\n",
    "X.append(su_truck)\n",
    "X.append(work_van)\n",
    "\n",
    "\n",
    "# X_name = training_name (the numbers --> 00053672, etc)\n",
    "X_name = []\n",
    "X_name.append(artic_truck_name)\n",
    "X_name.append(background_name)\n",
    "X_name.append(bicycle_name)\n",
    "X_name.append(bus_name)\n",
    "X_name.append(car_name)\n",
    "X_name.append(motorcycle_name)\n",
    "X_name.append(nonM_vehicle_name)\n",
    "X_name.append(pedes_name)\n",
    "X_name.append(pickup_truck_name)\n",
    "X_name.append(su_truck_name)\n",
    "X_name.append(work_van_name)\n",
    "\n",
    "# X_label = training_label (artic_truck = 0, background = 1,....)\n",
    "X_label= []\n",
    "length = 0\n",
    "for i in range(11):\n",
    "    if (i==2 or i==5 or i==6):\n",
    "        length = num_train_img1  #1700 for bicycle, motorcycle, nonM_vehicle\n",
    "    elif(i==4):\n",
    "        length = num_train_img3  #10000 for car\n",
    "    else:\n",
    "        length = num_train_img2  #5000 for all other categories\n",
    "    for j in range(length):\n",
    "        X_label.append(i)\n",
    "\n",
    "\n",
    "# superX = [[img_path1, name1, label1],[img_path2, name2, label2]......]\n",
    "superX = []\n",
    "element = []\n",
    "length = 0\n",
    "total_length = 0\n",
    "for i in range(11):\n",
    "    if (i==2 or i==5 or i==6):\n",
    "        length = num_train_img1  #1700 for bicycle, motorcycle, nonM_vehicle\n",
    "    elif(i==4):\n",
    "        length = num_train_img3  #10000 for car\n",
    "    else:\n",
    "        length = num_train_img2  #5000 for all the other categories\n",
    "    \n",
    "    for j in range(length):\n",
    "        element.append(X[i][j])\n",
    "        element.append(X_name[i][j])\n",
    "        element.append(X_label[total_length+j])\n",
    "        superX.append(element)\n",
    "        element = []\n",
    "    total_length += length\n",
    "    print(i)   # print the iteration number to indicate the loading progress\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the getHoG() function, which extracts HoG features of the input image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a function that takes list of images as input\n",
    "def getHoG(image_list):\n",
    "    cell_size = (8, 8)   # h x w in pixels\n",
    "    block_size = (2, 2)  # h x w in cells\n",
    "    nbins = 8            # number of orientation bins\n",
    "    hog_feature = []\n",
    "    for element in image_list:\n",
    "        hog = cv2.HOGDescriptor(_winSize=(element.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                  element.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                        _blockSize=(block_size[1] * cell_size[1],\n",
    "                                    block_size[0] * cell_size[0]),\n",
    "                            _blockStride=(cell_size[1], cell_size[0]),\n",
    "                        _cellSize=(cell_size[1], cell_size[0]),\n",
    "                        _nbins=nbins)\n",
    "        n_cells = (element.shape[0] // cell_size[0], element.shape[1] // cell_size[1])\n",
    "    \n",
    "        hog_feats = hog.compute(element)\\\n",
    "                   .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                        n_cells[0] - block_size[0] + 1,\n",
    "                        block_size[0], block_size[1], nbins) \\\n",
    "                   .transpose((1, 0, 2, 3, 4))  # index blocks by rows first \n",
    "    \n",
    "        gradients = np.full((n_cells[0], n_cells[1], 8), 0, dtype=float)\n",
    "        cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "    \n",
    "        for off_y in range(block_size[0]):\n",
    "            for off_x in range(block_size[1]):\n",
    "                gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                      off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                hog_feats[:, :, off_y, off_x, :]\n",
    "                cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                       off_x:n_cells[1] - block_size[1] + off_x + 1] += 1 \n",
    "        gradients /= cell_count\n",
    "        gradients = np.reshape(gradients, gradients.size)\n",
    "        hog_feature.append(gradients) \n",
    "    return hog_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the HoG features, names and labels needed for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract images from X and labels from X_label\n",
    "\n",
    "img_total_X = []\n",
    "length_X = 0\n",
    "for i in range(11):\n",
    "    if (i==2 or i==5 or i==6):\n",
    "        length_X = num_train_img1  #1700 for bicycle, motorcycle, nonM_vehicle\n",
    "    elif(i==4):\n",
    "        length_X = num_train_img3  #10000 for car\n",
    "    else:\n",
    "        length_X = num_train_img2  #5000 for all the other categories\n",
    "    \n",
    "    for j in range(length_X):\n",
    "        image_X = cv2.imread(X[i][j])\n",
    "        image_X = cv2.cvtColor(image_X, cv2.COLOR_BGR2GRAY)\n",
    "        image_X = cv2.resize(image_X, (128, 128))\n",
    "        img_total_X.append(image_X)\n",
    "\n",
    "\n",
    "# extract HoG features from the training images\n",
    "total_hog_X = getHoG(img_total_X)\n",
    "total_hog_X = np.asarray(total_hog_X)\n",
    "\n",
    "# extract the training image labels\n",
    "total_label_X = X_label.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Classify the Images Generated by the Localizer\n",
    "#### Compute accuracy, prediction, recall, and comfusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.26811594202898553\n",
      "precision: 0.26811594202898553\n",
      "recall: 0.26811594202898553\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the ground truth labels from csv file\n",
    "f = open('./crop_img_label.csv')\n",
    "csv_label = csv.reader(f)\n",
    "\n",
    "gt_label = []\n",
    "for row in csv_label:\n",
    "    label = int(row[1])\n",
    "    gt_label.append(label)\n",
    "    \n",
    "gt_label = np.asarray(gt_label)\n",
    "\n",
    "# read cropped images from localizer\n",
    "crop_img_array = []    \n",
    "for path in glob.glob(\"./crop_image/*.jpg\"):\n",
    "    crop_img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2GRAY)\n",
    "    crop_img = cv2.resize(crop_img, (128, 128))\n",
    "    crop_img_array.append(crop_img)\n",
    "\n",
    "crop_img_array = np.asarray(crop_img_array)\n",
    "\n",
    "# calculate HoG features for cropped images\n",
    "hog_crop_img = getHoG(crop_img_array)\n",
    "hog_crop_img = np.asarray(hog_crop_img)\n",
    "\n",
    "# train the logistic_regression_classifier and calculate prediction using cropped images\n",
    "log_crop = LogisticRegression()\n",
    "log_crop.fit(total_hog_X, total_label_X)\n",
    "prediction_crop = log_crop.predict(hog_crop_img)   \n",
    "\n",
    "# calculate accuracy\n",
    "correct = 0\n",
    "for i in range(len(prediction_crop)):\n",
    "    if prediction_crop[i] == gt_label[i]:\n",
    "        correct += 1\n",
    "accuracy_crop = correct/len(prediction_crop)\n",
    "\n",
    "# calculate precision\n",
    "precision_crop = precision_score(gt_label, prediction_crop, average='micro') \n",
    "\n",
    "# calcualte recall\n",
    "recall_crop = recall_score(gt_label, prediction_crop, average='micro')  \n",
    "\n",
    "# calculate confustion matrix\n",
    "conf_crop = confusion_matrix(gt_label, prediction_crop)\n",
    "\n",
    "# display the calculated accuracy, precision, recall and confusion matrix\n",
    "print(\"accuracy:\",accuracy_crop)\n",
    "print(\"precision:\", precision_crop)\n",
    "print(\"recall:\", recall_crop)\n",
    "plt.figure()\n",
    "plt.imshow(conf_crop)\n",
    "plt.title(\"Confusion Matrix of Localizer Cropped Images\"), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Is there a difference between using localizer + classifier vs. classification data + classifier?\n",
    "The accuracy, precision and recall are lower compared to the combination of classification data and classifier. This is because the results from the localizer are not accurate and there might be a mismatch between the actual cropped image and the ground truth label. In addition, there might be more than one object that are contained in the cropped images. \n",
    "\n",
    "#### -Should the ‘background’ label of the classifier be included when evaluating the performance of the localizer? \n",
    "Yes. Theoretically, the classifier from Section 2 can be used directly to classify the cropped images. Ideally, the classified labels should not contain any ‘background’ labels, because the localizer should not crop the background out theoretically. However, in our case, there are some cars recognized as ‘background’ and there are a couple of reasons for this. First, our classifier is not perfect (only has accuracy of about 60%). Second, the cropped images that the localizer generated may contain a lot of ground, and relatively less portions of the cars (this can also be shown from our low DICE coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
